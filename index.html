<!doctype html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>A4: GP2 Webpage</title>

<!--Remy Sharp Shim --> 
<!--[if lte IE 9]> 
<script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js" type="text/javascript" >
</script> 
<![endif]-->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
<script type="text/javascript">
/*makes the cover slide down up*/
$(document).ready(function(){
    $(".btn1").click(function(){
        $(".cover").slideUp();
    });
    $(".btn2").click(function(){
        $(".cover").slideDown();
    });
	
/*full screen slideshow*/
	$(".fullscreen-button").click(function(){
        $(".slideshow-container").toggleClass('fullscreen');
    });
	

/*This gets the IP info*/
	$.get("https://ipinfo.io/json", function (response) {
		$("#ip").html("IP: " + response.ip);
		$("#address").html("Location: " + response.city + ", " + response.region);
		$("#details").html(JSON.stringify(response, null, 4));
	}, "jsonp");

/*styles IP address card*/
	$("#flip").click(function(){
		$("#panel").slideToggle();
	}); 


/*This hides the cover page once a link is selected*/

	$(".hide").click(function() {
		$(".cover").hide();
	});

	
//Basic script used from http://jsfiddle.net/XQ9kY/1/

	var totalFirstResult = 0;
	var totalSecondResult = 0;
	var totalSideResult = 0;
	var totalThirdResult = 0;
	var totalFourthResult = 0;
	var totalFifthResult = 0;

	$('#first').hover(   
		function(){       
			$(this).data('inTime', new Date().getTime());
		},    
		function(){       
			var outTime = new Date().getTime();       
			var firstTime = (outTime - $(this).data('inTime'))/1000;
			totalFirstResult = totalFirstResult + firstTime;
			$('#firstResult').html('You hovered over the topmost part for ' + totalFirstResult.toFixed(2) + ' seconds. The last time you hovered here was: ' + totalFirstResult.toFixed(2) + ' seconds long.');
		}
	);
	$('#second').hover(   
		function(){       
			$(this).data('inTime', new Date().getTime());
		},    
		function(){       
			var outTime = new Date().getTime();       
			var secondTime = (outTime - $(this).data('inTime'))/1000;
			totalSecondResult = totalSecondResult + secondTime;
			$('#secondResult').html('You gazed upon the top box for ' + totalSecondResult.toFixed(2) + ' seconds. The last time you hovered here was ' + secondTime.toFixed(2) + ' seconds long.');
		}
	);
	$('#side').hover(   
		function(){       
			$(this).data('inTime', new Date().getTime());
		},    
		function(){       
			var outTime = new Date().getTime();       
			var sideTime = (outTime - $(this).data('inTime'))/1000;        
			totalSideResult = totalSideResult + sideTime;
			$('#sideResult').html('You stared at the side for ' + totalSideResult.toFixed(2) + ' seconds. The last time you hovered here was ' + sideTime.toFixed(2) + ' seconds.');
		}
	);
	$('#third').hover(   
		function(){       
			$(this).data('inTime', new Date().getTime());
		},    
		function(){       
			var outTime = new Date().getTime();       
			var thirdTime = (outTime - $(this).data('inTime'))/1000;
			totalThirdResult = totalThirdResult + thirdTime;			
			$('#thirdResult').html('You read the slideshow for ' + totalThirdResult.toFixed(2) + ' seconds. The last time you hovered here was '+thirdTime.toFixed(2) + ' seconds.');
		}
	);
	$('#fourth').hover(   
		function(){       
			$(this).data('inTime', new Date().getTime());
		},    
		function(){       
			var outTime = new Date().getTime();       
			var fourthTime = (outTime - $(this).data('inTime'))/1000;
			totalFourthResult = totalFourthResult + fourthTime;			
			$('#fourthResult').html('You were wondering about this cool part for ' + totalFourthResult.toFixed(2) + ' seconds. The last time you hovered here was ' + fourthTime.toFixed(2) + ' seconds.');
		}
	);
//end hover

	
	
//This makes the screen scroll back to top on refresh

    $('html, body').scrollTop(0);

    $(window).on('load', function() {
    setTimeout(function(){
        $('html, body').scrollTop(0);
    }, 0);
});
//end scroll top

});
</script>

<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="basic.css">

</head>

<body>


<div class="cover">

<img src="images/cover.jpg" alt="cover image" id="cover-image" />
<div class="shadow"><div class="btn1"></div></div>
</div>



<div class="container">

<div id="first">
</div>

<div id="side">
<div id="sideCont">
<h1>Relevant Videos</h1>
<iframe
src="https://www.youtube.com/embed/ENWVRcMGDoU">
</iframe>

<iframe
src="https://www.youtube.com/embed/UG_X_7g63rY">
</iframe>

<iframe
src="https://www.youtube.com/embed/JAuFC2mLlMg">
</iframe>

<iframe
src="https://www.youtube.com/embed/rE3j_RHkqJc">
</iframe>
</div>
</div>


<div id="second">

<!--<img id="ex" src="images/exampleimage.jpg" alt="example"/>-->

</div>



<div id="third">

<div class="slideshow-container">
<p class="fullscreen-button">Full Screen</p>

<div class="mySlides fade">
         <div class="numbertext">1 / 10</div>
         <h1 class="bullet">Introduction</h1>
         <p class="bullet">It's been said that <a href="https://www.economist.com/news/briefing/21721634-how-it-shaping-up-data-giving-rise-new-economy">"data [is] to this century what oil was to the last one: a driver of growth and change"</a>.</p>
         <p class="bullet">This new emphasis on data is not simply a reflection of its increased importance: there has been a qualitative change in the type of data that matters.</p>
         <p class="bullet"><i>"The quality of data has changed, too. They are no longer mainly stocks of digital information-databases of names and other well-defined personal data, such as age, sex and income. The new economy is more about analysing rapid real-time flows of often unstructured data: the streams of photos and videos generated by users of social networks, the reams of information produced by commuters on their way to work, the flood of data from hundreds of sensors in a jet engine."</i></p>
         <p class="bullet">This new type of data is characterized by its tremendous volume, and the speed at which it often needs to be parsed. This leap requires that new sense making tools be used to produce valuable and timely insight out of this overabundance of new and increasingly complex data. At the heart of these new tools are algorithms designed to find patterns where most of us would only see noise. The explosive growth of computerized databases, social media, sensor-laden mobile devices and ubiquitous IOT (Internet of Things) devices has resulted in a world where, increasingly,  our every move is observed, cataloged and evaluated by algorithms who then make decisions that have serious repercussions on the lives of the people they are watching, or even just connected to the people being watched.</p>
         <p class="bullet">While it's neither possible nor desirable to stop this trend<sup>1</sup>, we think it's important to understand some of the possible problems that can occur when these algorithms are used indiscriminately and without the proper safeguards or a solid understanding of where they can fail. We are also concerned about us not yet having the right social and legal infrastructure to deal with these problems when the arise.</p>
         <p class="bullet">We'll be looking at how algorithms are having a growing impact on the legal, financial and social areas of the world around us, and illustrating several different kinds of flaws or limitations to which algorithms are particularly susceptible.</p>
         <b><p>1. The speed and efficiency gains that are made possible by the use of cheap and omnipresent sensors, interconnected computing resources and the right algorithms to make all of it work together are so significant that it seems unlikely that we can get everyone to agree to forgo these gains. Furthermore, in the current economic and environmental context, rejecting these efficiency gains could have disastrous consequences.</p></b>
      </div>
      <div class="mySlides fade">
         <div class="numbertext">2 / 10</div>
         <h1 class="bullet">Legal Impact</h1>
         <p class="bullet">Algorithms are already being used to help judges decide on sentences. In some places, they are even being used as an alternative to posting <a href="https://www.economist.com/news/united-states/21731631-new-jersey-has-bold-experiment-reduce-number-people-jail-awaiting">bail</a> and the trend is growing.</p>
         <p class="bullet">They are also deciding where policing is most <a href="https://www.technologyreview.com/s/428354/la-cops-embrace-crime-predicting-algorithm/">aggressive</a>. Unlike their human predecessors, they aren't just looking at crime data, they are looking at location data (among other things) from people who aren't even directly <a href="https://www.forbes.com/sites/parmyolson/2012/08/06/algorithm-aims-to-predict-crime-by-tracking-mobile-phones/#1e1b86da496e">involved</a>. Facebook has also been algorithmically monitoring its users to catch online predators. While the goal is laudable and it seems to have prevented at least a few crimes, it's concerning when a social media company who manipulates its users' interactions as part of its business model also starts selectively reporting some of their actions to law enforcement, based on what it deems <a href="https://www.forbes.com/sites/parmyolson/2012/08/06/algorithm-aims-to-predict-crime-by-tracking-mobile-phones/#1e1b86da496">"shifty"</a>.</p>
         <p class="bullet">Algorithms are increasingly being used in the legal field, having taken over huge chunks of discovery and <a href="https://www.npr.org/sections/alltechconsidered/2017/11/07/561631927/from-post-it-notes-to-algorithms-how-automation-is-changing-legal-work">research</a>. Most of the litigation and negotiation is still being carried out by humans, but they are working off of the evidence found by algorithms.</p>
      </div>
      <div class="mySlides fade">
         <div class="numbertext">3 / 10</div>
         <h1 class="bullet">Financial Impact</h1>
         <p class="bullet">Social credit systems work as a <a href="https://en.wikipedia.org/w/index.php?title=Mass_surveillance_tool&action=edit&redlink=1">mass surveillance tool</a> and use <a href="https://en.wikipedia.org/wiki/Big_data_analysis">big data analysis</a> <a href="https://en.wikipedia.org/wiki/Technology">technology</a>. The system will give users a numeric rating based in part on their <a href="https://qz.com/1049669/chinas-tencent-hkg-0700-is-quietly-testing-a-social-credit-score-based-on-peoples-online-behavior/">spending habits</a>.</p>
         <p class="bullet">While the normal credit cards, car loans, and mortgages are a factor the system incorporates the online items you buy, the restaurants you visit, as well as the movies and money transfers you make. Store purchases can negatively impact someone's credit score so people have to be conscious of the items they buy.  In such a system one would have to be conscious of what they buy and whether the government would view it favorably or not. Even your friends' spending activities could lead to your own negative ratings.</p>
         <p class="bullet">We're seeing the start of how they are being used as a mass surveillance tool that collects data and then uses that information as a way to determine things such as how much you can have on a loan or much your insurance plan will cost.</p>
         <p class="bullet">Credit is not the only financial instrument affected, your ability to get insurance also depends on the scores you receive from these algorithms. In countries like the United States where public transit and public health care aren't available to all, your ability to get health care or car insurance could end up being impacted by the purchasing decisions of your Facebook friends.</p>
      </div>
      <div class="mySlides fade">
         <div class="numbertext">4 / 10</div>
         <h1 class="bullet">Social Impact</h1>
         <p class="bullet">Social scores could be affected by more than the transactions we make.  Media sites are able to use algorithms to target us through our friends and the people that we follow.  The friends you choose to keep will affect your social ratings.</p>
         <p class="bullet">In China many people are dismayed by recent advances in the social credit system.  Some view it as way of restricting their activities.  Penalties for not pursuing preferred activities by the state are a real issue.  On the other hand some citizens are treating it like a popularity contest trying to get the highest score.  Dating sites could post your information and the government can share your scores online to the public as well to curb your activities.</p>
         <p class="bullet">It's interesting to see how social media sites are able to use algorithms to target us through our friends and the people that we follow. Namely, in the way that they filter through information for us. Though the idea of posting more content and seeing more like it seems rather straightforward, it often leads us to only see what we want to see online, thus causing polarizing views based on demographic information. This metaphorical "preaching to the choir" often leads users unable to see posts done by close family members with slightly differing views.</p>
         <p class="bullet">Further reading:
         <ul>
         <li><a href="http://www.newsweek.com/algorithm-lie-city-university-478815">Lie On Your Dating Profile? This Algorithm Will Know</a></li>
         </ul></p>
      </div>
      <div class="mySlides fade">
         <div class="numbertext">5 / 10</div>
         <h1 class="bullet">Error Sources: Bias</h1>
         <p class="bullet">There have been instances of sentencing algorithms recreating racist because of how they were trained, even when the algorithm does not directly look at race and only works with data that correlates to race
            <sup><a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">2</a>, <a href="https://mic.com/articles/144084/propublica-courts-use-a-racially-biased-formula-to-predict-future-criminals#.RgWo8uNsl">3</a>, <a href="https://theoutline.com/post/1571/the-fight-against-racist-algorithms">4</a>, <a href="https://www.washingtonpost.com/news/monkey-cage/wp/2016/10/17/can-an-algorithm-be-racist-our-analysis-is-more-cautious-than-propublicas/?utm_term=.cfae6486ba27">5</a></sup>.
         </p>
         <p class="bullet">Google is also more likely to show <a href="https://www.washingtonpost.com/news/the-intersect/wp/2015/07/06/googles-algorithm-shows-prestigious-job-ads-to-men-but-not-to-women-heres-why-that-should-worry-you/?utm_term=.c2ef79210ccb">ads for high-paying executive jobs</a> to men.</p>
         <p class="bullet">Further reading:
         <ul>
         <li><a href="https://www.theguardian.com/technology/2016/aug/03/algorithm-racist-human-employers-work">Is an algorithm any less racist than a human? </a></li>
         <li><a href="https://www.npr.org/2016/03/14/470427605/can-computers-be-racist-the-human-like-bias-of-algorithms">Can Computers Be Racist? The Human-Like Bias Of Algorithms</a>
         </li>
         <li><a href="https://www.wired.com/2017/02/keep-ai-turning-racist-monster/">How to Keep Your AI From Turning Into a Racist Monster</a></li>
         <li><a href="http://www.akapellaconsulting.com/the-dangers-of-machine-learning-in-healthcare/">The Dangers of Machine Learning in Healthcare</a></li></ul></p>
      </div>
      <div class="mySlides fade">
         <div class="numbertext">6 / 10</div>
         <h1 class="bullet">Error Sources: Flawed Recognition</h1>
         <p class="bullet">Adversarial images have been used to fool machine learning algorithms. Changing a single pixel on an image of a turtle led Google to think it was a gun<sup><a href="https://www.theverge.com/2017/11/2/16597276/google-ai-image-attacks-adversarial-turtle-rifle-3d-printed">6</a>,<a href="http://www.popularmechanics.com/technology/news/a28876/machine-learning-image-recognition-adversarial-examples/">7</a></sup>. This is worrisome for the obvious reason that these algorithms can easily be tricked but also that if a single pixel can so easily foil the algorithm, as simple bit flip on the image file or a stuck pixel on the camera sensor might, on a large enough sample, produce the same results.</p>
         <p class="bullet">Google image recognition has also confused humans with gorillas<sup><a href="https://www.cnet.com/news/google-apologizes-for-algorithm-mistakenly-calling-black-people-gorillas/">8</a>,<a href="https://www.wnyc.org/story/deep-problem-deep-learning/">9</a></sup>, which ties back to the racism issue but also presents a pretty galling recognition error of its own.</p>
         <p class="bullet">There have also been cases of algorithms being fooled by random shapes or textures<sup><a href="https://www.theverge.com/2017/4/12/15271874/ai-adversarial-images-fooling-attacks-artificial-intelligence">10</a></sup>, badly mistaken road sign identification and animals being muddled to a degree that would probably some toddlers laugh<sup><a href="https://spectrum.ieee.org/cars-that-think/transportation/sensors/slight-street-sign-modifications-can-fool-machine-learning-algorithms">11</a></sup>.</p>

         <p class="bullet">Further reading:
            <ul>
            <li><a href="https://cosmosmagazine.com/society/dangers-of-unregulated-ai-and-robots-loom">Dangers of unregulated AI and robots loom</a></li>
            <li><a href="http://www.louisdorard.com/blog/when-machine-learning-fails">When Machine Learning fails</a></li>
            <li><a href="ttps://www.forbes.com/sites/valleyvoices/2016/11/16/cutting-through-the-machine-learning-hype/">Cutting Through The Machine Learning Hype</a></li>
            <li><a href="http://www.bbc.com/news/technology-41845878">AI image recognition fooled by single pixel change</a></li>
         </ul>
         </p>
      </div>
      <div class="mySlides fade">
         <div class="numbertext">7 / 10</div>
         <h1 class="bullet">Error Sources: Not Understanding Context</h1>
         <p class="bullet">An area of particular concern has to do with the misunderstandings that can result from increasingly complex algorithms. Past a certain level of complexity, it becomes impossible for laypeople to understand the algorithm, and by extension, effectively question its results. We are even getting to a point where some algorithms are <a href="https://www.technologyreview.com/s/604087/the-dark-secret-at-the-heart-of-ai/">inscrutable even to domain experts</a>. This is problematic because algorithms lack both the human ability to understand context, and the ability to explain their reasoning to humans. This will likely lead to a situation where algorithms may make horribly misguided decisions and leave people unable to reason with, understand or appeal the process.</p>
         <p class="bullet">In a recent controversy over the censoring of a famous picture from the Vietnam War, Facebook blamed their software for the removal, which was only reversed after an international <a href="https://www.theverge.com/2016/9/9/12865670/facebook-censorship-napalm-girl-aftenposten-reversal">outcry</a>. There is nothing to suggest that the reversal would have occurred if the person being censored wasn't a famous journalist and the picture hadn't won a Pulitzer Prize. If you don't have enough power to force a human to pull rank on the algorithm, there is no recourse. Europe has already moved towards legislation that limits how people can be evaluated by automated decision making and requires explanations be provided in many instances of algorithmic decision making, but it's not clear how far reaching or effective this legislation might be </p>
         <p class="bullet">It's easy to forget that while algorithms replicate portions of human thought, they are not, at this point, conscious what they are doing or even remotely human in how they process information. They have no empathy, no self-awareness, no understanding of the purpose behind what they are doing, and no instincts that would allow them to deviate from whatever they have been optimized to do. They don't question what they do, can't be reasoned with, and can not be asked to justify their decisions in the way a human can. A human can intuitively understand that a picture showing a copy of Mein Kampf in a Holocaust Museum means something very different than a picture from the 1930s of the same book sitting on the shelf of a right-wing German political commentator. As they currently exist, algorithms would simply use optical character recognition to tag the book and possibly censor the picture if it isn't in the best interest of a company to have controversial pictures posted on their website. It's of course possible to enhance this algorithm by white listing some sources or setting a higher level of scrutiny for others, but doing so creates the kind of biased algorithm we spoke about in the previous section.</p>
         <p class="bullet">Further Reading:
            <ul>
               <li><a href="https://en.m.wikipedia.org/wiki/Right_to_explanation">Right to explanation</a></li>
               <li><a href="https://www.wired.com/insights/2013/04/with-big-data-context-is-a-big-issue/">With Big Data, Context is a Big Issue</a></li>
            </ul>
         </p>
      </div>
     <div class="mySlides fade">
         <div class="numbertext">8 / 10</div>
         <h1 class="bullet">Error Sources: Stolen/Shared Identity</h1>
			<p class="bullet">It&rsquo;s not unheard of to have users share their personal accounts between family members. Some companies, like <a href="https://techcrunch.com/2016/01/11/netflix-ceo-says-account-sharing-is-ok/">Netflix</a>, <a href="https://www.androidcentral.com/how-share-amazon-prime-friends-and-family">Amazon</a> and <a href="http://store.steampowered.com/promotion/familysharing">Steam</a>, encourages it and even go so far as to have clearly written out rules and benefits that are provided with sharing.</p>

         <p class="bullet">However, when you add in the fact that this shared info is getting tossed into the datapool, you, the tech geek of your family, will start getting little ads for frilly pink socks and lacy underwear that your daughter wants or creepy suggestions on Google. <a href="https://www.t3.com/features/what-google-knows-about-you">And things get really, really creepy.</a></p>

         <p class="bullet">Knowing this, there are potential things that people can look up on your shared account that is questionable or straight up illegal. And this information is now permanently tied to you.</p>

         <p class="bullet">In China, the government is proposing to use the algorithm to &ldquo;encourage&rdquo; good behavior with little perks like bumping up your dating profile, giving you hotel perks and better credit deal<a href="http://www.wired.co.uk/article/chinese-government-social-credit-score-privacy-invasion"><sup>12</sup></a>. While the perks might be seen as cool, the downsides are not. To the average person, this social credit will be used to punish those who act against the norm, and those who behave in a way deemed &ldquo;untrustworthy&rdquo; by the government. As Jacob Silverman (a New Republic journalist) puts it, &ldquo;...this &ldquo;mega-system&rdquo; ensures the financialization of everyday life, tying every choice and behavior to one's economic and social standing, is just another irony of China's brand of state-led corporatism.&rdquo; <a href="https://newrepublic.com/article/123285/chinas-troubling-new-social-credit-system-and-ours"><sup>13</sup></a></p>

         <p class="bullet">It's easy in these situations to blame the victim and simply suggest better security, but when companies don't require you to opt-in before they start tracking you, and don't have good security themselves, it's not clear what regular consumers can do. The recurring theme after the Equifax breach wasn't simply better security but constant monitoring <sup><a href="http://www.businessinsider.com/equifax-breach-credit-freeze-prevent-identity-theft-2017-9">14</a></sup>, <a href="https://www.consumer.ftc.gov/blog/2017/09/equifax-data-breach-what-do"><sup>15</sup></a>, <a href="https://www.creditcards.com/credit-card-news/equifax-breach-questions-and-answers.php"><sup>16</sup></a>, <sup><a href="http://fortune.com/2017/09/15/what-to-do-this-weekend-equifax/">17</a></sup> which is basically an admission that there is nothing you can do to protect yourself from a breach or identity theft in the first place. When identity security company CEO Todd Davis' identity has been stolen at least <a style="text-decoration: none;" href="https://www.wired.com/2010/05/lifelock-identity-theft/">thirteen times</a>, it not clear how the average person is meant to stay safe.</p>

         <p class="bullet">Among the countless examples of social media identity theft out there, several are the result of glaring loopholes in the security procedures put in place to protect them and show that no reasonable precautions can protect users from weak security practices at the companies that run these networks.</p>
      </div>
      <div class="mySlides fade">
         <div class="numbertext">9 / 10</div>
         <h1 class="bullet">Opting Out And Professional Implications</h1>
         <p class="bullet">As if these issues weren't sufficiently worrisome in the current context, where people have some measure of control over what they subject themselves to, there are already signs that not submitting yourself to these risks is itself being frowned upon. There is an increasingly popular line of reasoning that there is in fact something wrong with people who don't fully endorse and buy into this system. Some employers not only insist on seeing the Facebook profiles of prospective employees but refuse to evaluate candidates who don't have one. Some have even suggested that not having a Facebook account is a sign of something sinister. Even when those who shun mainstream are presented in a favorable light, it's still seen as an act of defiance of something unusual.</p>
         
         <p class="bullet">Further reading:
         	<ul>
         	<li><a href="http://www.dailymail.co.uk/news/article-2184658/Is-joining-Facebook-sign-youre-psychopath-Some-employers-psychologists-say-suspicious.html#ixzz4xbCJUemY">Is not joining Facebook a sign you're a psychopath? Some employers and psychologists say staying away from social media is 'suspicious'</a></li>
         	<li><a href="https://www.forbes.com/sites/kashmirhill/2012/08/06/beware-tech-abandoners-people-without-facebook-accounts-are-suspicious/#6b763ca88f95">Beware, Tech Abandoners. People Without Facebook Accounts Are 'Suspicious.'</a></li>
         	<li><a href="https://www.reddit.com/r/AskReddit/comments/1ar82p/denied_job_because_i_didnt_have_a_facebook/">Reddit: Denied job because I didn't have a Facebook account. What are my legal options?</a></li>
         	<li><a href="https://www.huffingtonpost.com/rachel-ryan/hiring-facebook_b_2795047.html">Yes, Employers Will Check Your Facebook Before Offering You a Job</a></li>
         	<li><a href="https://www.vogue.com/article/dark-on-social-media-abstainers">https://www.vogue.com/article/dark-on-social-media-abstainers</a>, <a href="">Is There Something Wrong With People Who Do Not Use Facebook?</a></li>
         	<li><a href="https://www.psychologytoday.com/blog/unique-everybody-else/201209/is-there-something-wrong-people-who-do-not-use-facebook">Is There Something Wrong With People Who Do Not Use Facebook?</a></li>
         	<li><a href="http://business.time.com/2012/08/08/does-not-having-a-facebook-page-make-you-suspicious-to-employers/">Does Not Having a Facebook Page Make You 'Suspicious' to Employers?</a></li>
            <li><a href="https://www.bloomberg.com/news/features/2017-11-15/the-brutal-fight-to-mine-your-data-and-sell-it-to-your-boss">The Brutal Fight to Mine Your Data and Sell It to Your Boss</a></li>
         </ul>
         </p>
      </div>
     <div class="mySlides fade">
         <div class="numbertext">10 / 10</div>
  <!--         <h1 class="bullet">Possible Scenarios</h1>
         <p class="bullet">You visit a Buddhist temple and get flagged as a Neo-Nazi.</p>
          <p class="bullet">You don't un-friend a high-school acquaintance because you hear they are having mental health issues. Their disturbed Facebook monologues impact a hiring algorithm looking through your profile to gauge "culture fit".</p>
          <p class="bullet">You come from a small town that was hit hard in the recession. Despite a promising career as a developer in Seattle, the credit score of your friends and family (which you are still connected to on social media) makes it impossible for you to afford a home.</p>
          <p class="bullet">A dead pixel leads an algorithm to mistakenly break a self-driving car when there was no need. You are rear-ended by the car behind you, which was piloted by a human with much slower reflexes. The whiplash does lasting damage.</p>
      </div>
      <div class="mySlides fade">
    <div class="numbertext">11 / 11</div>
   -->      <h1 class="bullet">Conclusion</h1>
      <p class="bullet">Ultimately, it's not a question of if, or even when algorithms will be used to make significant decisions that directly affect almost every facet of our lives. It's already happening, and we shouldn't dismiss the many benefits that these digital tools can grant us. However, as we've outlined here, there are many issues with regards to how these tools are implemented. Algorithms can be very efficient and powerful, but they can also be incredibly wrong. We hope that the issues we've brought up here can encourage discussion around the limitations of much of the algorithmic decision making that's happening right now, and let us all start thinking about what safeguards or checks and balances are needed going forward.</p>
   </div>


<a class="prev" onclick="plusSlides(-1)">&#10094;</a>
<a class="next" onclick="plusSlides(1)">&#10095;</a>

</div>
<br>

<div style="text-align:center">
  <span class="dot" onclick="currentSlide(1)"></span> 
  <span class="dot" onclick="currentSlide(2)"></span> 
  <span class="dot" onclick="currentSlide(3)"></span> 
  <span class="dot" onclick="currentSlide(4)"></span> 
  <span class="dot" onclick="currentSlide(5)"></span> 
  <span class="dot" onclick="currentSlide(6)"></span> 
  <span class="dot" onclick="currentSlide(7)"></span> 
  <span class="dot" onclick="currentSlide(8)"></span> 
  <span class="dot" onclick="currentSlide(9)"></span> 
  <span class="dot" onclick="currentSlide(10)"></span> 
  <span class="dot" onclick="currentSlide(11)"></span> 
  <span class="dot" onclick="currentSlide(12)"></span> 
  <span class="dot" onclick="currentSlide(13)"></span> 
  <span class="dot" onclick="currentSlide(14)"></span> 
  <span class="dot" onclick="currentSlide(15)"></span> 
</div>



<script>
var slideIndex = 1;
showSlides(slideIndex);

function plusSlides(n) {
  showSlides(slideIndex += n);
}

function currentSlide(n) {
  showSlides(slideIndex = n);
}

function showSlides(n) {
  var i;
  var slides = document.getElementsByClassName("mySlides");
  var dots = document.getElementsByClassName("dot");
  if (n > slides.length) {slideIndex = 1}    
  if (n < 1) {slideIndex = slides.length}
  for (i = 0; i < slides.length; i++) {
      slides[i].style.display = "none";  
  }
  for (i = 0; i < dots.length; i++) {
      dots[i].className = dots[i].className.replace(" active", "");
  }
  slides[slideIndex-1].style.display = "block";  
  dots[slideIndex-1].className += " active";
}
</script>
</div>

<div id="fourth">
<div id="trackerContainer">
<p id="tracker">Thanks for visiting! I hope you don't mind, but we've kept track of the sections you've visited: </p>


	<p>If you would like to see <input type="button" name="Submit" value="Click Here" onclick="document.getElementById('results').style.display = 'block' ;" /></p>
	<div id="results">
		<div id="firstResult"></div>
		<div id="sideResult"></div>
		<div id="thirdResult"></div>
		<div id="fourthResult"></div>
	</div></div>

	<div id="userInfo">
		<h1 id="flip">YOUR IP ADDRESS CARD:</h1>
		<div id="panel">
			<div id="ip"></div>
			<div id="address"></div>
			<div id="details"></div>
		</div>						
	</div>
</div>

<footer>
  <div id="footertxt"><small>&copy; 2017 by <a href="#" target="_blank" class="a4gp2">A4GP2</a>, All Rights Reserved ~ </small></div> <a href="" target="_blank"><img class="valid" src="http://edison.seattlecentral.edu/~Hanbo.Yoon/itc134_images/html5.png" style="width:45px;height:45px" alt="html5 badge logo"></a>  
<a href="" target="_blank"><img class="valid" src="http://edison.seattlecentral.edu/~Hanbo.Yoon/itc134_images/css.png" style="width:45px;height:45px" alt="css badge logo" ></a>
</footer>

</div>
</body>
</html>